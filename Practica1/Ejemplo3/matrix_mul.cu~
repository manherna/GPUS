#include <stdio.h>
#include "matrix_mul.h"

// Thread block size
#define BLOCK_SIZE 16 

// Forward declaration of the device multiplication function
__global__ void Muld(float*, float*, int, int, float*);

// Host multiplication function
// Compute C = A * B
// hA is the height of A
// wA is the width of A
// wB is the width of B

//export void Mul(float*, float*, int, int, int, float*);

 void Mul(float* A, float* B, int hA, int wA, int wB,
	float* C)
{
	float *d_A, *d_B, *d_C;/*......*/
	dim3 block(BLOCK_SIZE,BLOCK_SIZE); /*..........*/	
	dim3 grid(2,2);/*..........*/


	int size_A = wA * hA*sizeof(float);
	int size_B = wB * hA*sizeof(float);
	int size_C = wB * hA*sizeof(float);

	cudaMalloc((void**)&d_A, size_A); /*......*/
	cudaMalloc((void**)&d_B, size_B);
	cudaMalloc((void**)&d_C, size_C);


	cudaMemcpy(d_A,A,size_A,cudaMemcpyHostToDevice); /*......*/
	cudaMemcpy(d_B,B,size_B,cudaMemcpyHostToDevice);

	Muld<<<grid,block>>>(d_A, d_B, wA, wB, d_C);

	cudaMemcpy(C,d_C,size_C,cudaMemcpyDeviceToHost);

	cudaFree(d_A); cudaFree(d_B); cudaFree(d_C); /*......*/
}

// Device multiplication function called by Mul()
// Compute C = A * B
// wA is the width of A
// wB is the width of B
__global__ void Muld(float* A, float* B, int wA, int wB, float* C)
{
	// Block index
	int bx = blockIdx.x;
	int by = blockIdx.y;

	// Thread index
	int tx = threadIdx.x;
	int ty = threadIdx.y;

	__shared__ float As [BLOCK_SIZE][BLOCK_SIZE];
	__shared__ float Bs [BLOCK_SIZE][BLOCK_SIZE];
	
	int aIni = wA * BLOCK_SIZE * by;
	int bIni = bx * wA * BLOCK_SIZE;	
	
	int aFin = aIni + wA-1;

	float valor = 0.0;
	for(int a = aIni, b = bIni; a <= aFin; a+= BLOCK_SIZE, b+= wA*BLOCK_SIZE){
		
	As[ty][tx] = A [a+tx+wA*ty];
	Bs[ty][tx] = B [b+tx+wA*ty];

	__syncthreads();
	
	for(int i = 0; i < BLOCK_SIZE; i++) 
	valor+= As [ty][i] * Bs [i][tx];
	
	
	__syncthreads();
	}
	int blockOut = wA * BLOCK_SIZE * by + BLOCK_SIZE * bx;
	C[blockOut+ wA*ty +tx] = valor;
	




/*
	// Index of the first sub-matrix of A processed by the block 
	int aBegin = wB*BLOCK_SIZE*by; /* ..........................

	// Index of the last sub-matrix of A processed by the block
	int aEnd = aBegin + wB -1; /* ..........................

	// Step size used to iterate through the sub-matrices of A
	int aStep = BLOCK_SIZE;

	// Index of the first sub-matrix of B processed by the block
	int bBegin = BLOCK_SIZE * bx;

	// Step size used to iterate through the sub-matrices of B
	int bStep = BLOCK_SIZE * wIB;

	// The element of the block sub-matrix that is computed
	// by the thread
	float Csub = 0;
	// Shared memory for the sub-matrix of A
	__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];

		// Shared memory for the sub-matrix of B
	__shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];
	// Loop over all the sub-matrices of A and B required to
	// compute the block sub-matrix
	for (int a = aBegin, b = bBegin; a <= aEnd; a += aStep, b += bStep) {
		

		// Load the matrices from global memory to shared memory;
		// each thread loads one element of each matrix
		As[ty][tx] = A[a + wB *ty + tx]; /* ..........................
		Bs[ty][tx] = B[b + wB *ty + tx]; /* ..........................
		// Synchronize to make sure the matrices are loaded
		__syncthreads();

		// Multiply the two matrices together;
		// each thread computes one element
		// of the block sub-matrix
		for (int k = 0; k < BLOCK_SIZE; ++k)
			Csub += As[ty][k] * Bs[k][tx];/* ..........................

		// Synchronize to make sure that the preceding
		// computation is done before loading two new
		// sub-matrices of A and B in the next iteration
		__syncthreads();
	}
	
	// Write the block sub-matrix to global memory;
	// each thread writes one element
	
	int out = wB * BLOCK_SIIZE * by + BLOCK_SIZE * bx;
	C[out + wB *ty + tx] = Csub;

	/* ..........................*/
}


//	float *d_A, *d_B, *d_C;/*......*/
//	float *h_A, *h_B, *h_C;/*......*/
//	dim3 block(BLOCK_SIZE,BLOCK_SIZE); /*..........*/	
//	dim3 grid(2,2);/*..........*/


//	int size_A = wA * hA;
//	int size_B = wB * wA;
//	int size_C = wB * hA;
//	cudaMalloc((void**)&d_A, size_A); /*......*/
//	cudaMalloc((void**)&d_B, size_B);
//	cudaMalloc((void**)&d_C, size_C);

//	h_A = (float*)malloc(size_A*sizeof(float)); /*......*/
//	h_B = (float*)malloc(size_B*sizeof(float));
//	h_C = (float*)malloc(size_C*sizeof(float));

//	cudaMemcpy(d_A,h_A,size_A,cudaMemcpyHostToDevice); /*......*/
//	cudaMemcpy(d_B,h_B,size_B,cudaMemcpyHostToDevice);

//	Muld<<<grid,block>>>(d_A, d_B, wA, wB, d_C);
//	cudaMemcpy(C,d_C,size_C,cudaMemcpyDeviceToHost);

//	cudaFree(d_A); cudaFree(d_B); cudaFree(d_C); /*......*/
//	free(h_A); free(h_B); free(h_C);
